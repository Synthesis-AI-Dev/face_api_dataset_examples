{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A9Tv1YwlOKf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Camera intrinsics, screen coordinates and 3D data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwqIVXkalOKj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first, we install `face_api_dataset` other dependencies and download test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJ8kGUhclOKk",
    "outputId": "7ac6fb2a-ceb5-4e67-af05-51d53f005753",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1281  100  1281    0     0   1479      0 --:--:-- --:--:-- --:--:--  1500\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   241  100   241    0     0    616      0 --:--:-- --:--:-- --:--:--   632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Synthesis-AI-Dev/face_api_dataset.git@058ebef3 (from -r /var/folders/4h/2fr255s9115drx7nckt7bb6m0000gp/T/tmp.hM2N3laU/requirements.txt (line 1))\n",
      "  Cloning https://github.com/Synthesis-AI-Dev/face_api_dataset.git (to revision 058ebef3) to /private/var/folders/4h/2fr255s9115drx7nckt7bb6m0000gp/T/tmp.hM2N3laU/pip-req-build-1cr8kilb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/Synthesis-AI-Dev/face_api_dataset.git /private/var/folders/4h/2fr255s9115drx7nckt7bb6m0000gp/T/tmp.hM2N3laU/pip-req-build-1cr8kilb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -o \"setup.sh\" https://raw.githubusercontent.com/Synthesis-AI-Dev/face_api_dataset_examples/main/setup.sh\n",
    "chmod a+x setup.sh\n",
    "./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0ENhjh7lOKn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we add some imports for the visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFX2XjHzlOKn",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGnaMPDGlOKo",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tP2qdZElOKo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use `FaceApiDataset` class to access synthesis datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKksnQXwlOKp",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from face_api_dataset import FaceApiDataset, Modality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUD5p25rlOKp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Warning!** Some of modalities requires additional libraries to be installed:\n",
    "`SEGMENTS` and `RGB` modalities use `opencv-python` library,\n",
    " while `DEPTH`, `ALPHA` and `NORMALS` modalities\n",
    " use `tiffile`  and `imagecodecs` libraries for effective work with floating point tiff files.\n",
    " If dataset with these modalities will be created without corresponding libraries present, an `ImportError` is raised.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9u9UCO7lOKp",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_root = \"test_dataset\"\n",
    "dataset = FaceApiDataset(data_root,\n",
    "                        modalities=[Modality.RGB,\n",
    "                                    Modality.CAM_INTRINSICS,\n",
    "                                    Modality.LANDMARKS_3D_IBUG68,\n",
    "                                    Modality.LANDMARKS_IBUG68,\n",
    "                                    Modality.DEPTH,\n",
    "                                    Modality.LANDMARKS_3D_MEDIAPIPE_FACE,\n",
    "                                    Modality.LANDMARKS_3D_SAI\n",
    "                                   ])\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEQaIO8FlOKq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are 13 items in the test dataset. Let's explore them closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IciJVCYUlOKq",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "item = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkP6AmialOKq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each item is a dict with different modalities as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whZHa_tnlOKq",
    "outputId": "4622e710-2604-4e95-8604-0461cd6a5fd7",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hQjB6cZlOKr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we explore camera intrinsics and transistion between 3D and the screen coordinate systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmR_j662lOKr",
    "outputId": "20918b07-350f-4db9-b2e7-aef546330533",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "intrinsics = item[Modality.CAM_INTRINSICS]\n",
    "intrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvtp25EslOKr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The camera intrinsics are in OpenCV format:\n",
    "$$\\left [ \\begin{matrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{matrix} \\right ]$$,\n",
    "where $f_x$ and $f_y$ are focal distances and $c_x$ and $c_y$ is an optical center\n",
    "(2D coordinates of the point, camera is pointing at on the image).\n",
    "\n",
    "Note, that units of distance in 3D are meters and units in 2D are pixels, the conversion coefficient is already included in $f_x$.\n",
    "\n",
    "$c_x$ and $c_y$ are usually equal to the half of the image resolution as camera is normally pointing to the center of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soLq4Q8RlOKr",
    "outputId": "09029502-9a14-4bb5-f015-86935e522b79",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.array(item[Modality.RGB].shape[:2]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DSwpKqilOKs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can convert between camera and screen coordinate systems. Let's see how it is done, using ibug68 landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwuXyAWXlOKs",
    "outputId": "165d45a9-296a-4da7-a96e-04a20642dc03",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "landmark_0 = item[Modality.LANDMARKS_3D_IBUG68][0]\n",
    "landmark_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFOZNUUrlOKs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first, we need to check that landmark is in front of the camera (z coordinate is negative):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESzd3duolOKs",
    "outputId": "002dc9f3-3bc3-482d-fc18-41a563df7201",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "landmark_0[2] < 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmbquIFnlOKs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can convert to screen coordinate system, using intrinsic matrix. However, our 3D camera coordinate system uses OpenGL axis (x right, y top, z towards the camera), and OpenCV system uses a different [one](https://docs.opencv.org/4.5.3/d9/d0c/group__calib3d.html) (x right, y bottom, z from the camera).\n",
    "Thus before we apply the conversion, we need to convert between this coordinate systems, otherwise screen coordinates will be mirrored vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQUmu9BVlOKt",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def opengl_to_opencv(x):\n",
    "    return np.array(x) * [1, -1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEj0EyfzlOKt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To compute landmark in screen coordinates we need to multiply 3D coordinates by the intrinsic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYGN6_OglOKt",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def cam_to_hom_screen(intrinsics, x):\n",
    "    return np.tensordot(opengl_to_opencv(x), intrinsics, axes=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zE0PMYYTlOKt",
    "outputId": "b4eea488-c96d-4f4d-e420-04a5314c5c91",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cam_to_hom_screen(intrinsics, landmark_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6HQEtRwlOKt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the result, but it is in homogeneous coordinates. We need to convert it to euclidian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJvOvoJSlOKt",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def from_homogeneous_2D(xs):\n",
    "    xs_array = np.array(xs)\n",
    "    assert (xs_array.shape[-1] == 3)\n",
    "\n",
    "    slice_but_last = [slice(None)] * (xs_array.ndim - 1) + [slice(None, -1)]\n",
    "    slice_but_last = tuple(slice_but_last)\n",
    "\n",
    "    slice_last = [slice(None)] * (xs_array.ndim - 1) + [slice(-1, None)]\n",
    "    slice_last = tuple(slice_last)\n",
    "    return xs_array[slice_but_last] / xs_array[slice_last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z77FqPElOKt",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def cam_to_screen(intrinsics, x):\n",
    "    return from_homogeneous_2D(cam_to_hom_screen(intrinsics, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykp8ls2ylOKu",
    "outputId": "921e33e1-8db2-47ba-8856-f4b2317460d7",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cam_to_screen(intrinsics, landmark_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKW1TkWDlOKu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To check ourselves, let's compare with 2D location of this landmark we get from the info.json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfiGgNUjlOKu",
    "outputId": "ffc6707c-1f34-45d2-d47c-2b234955fc62",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.LANDMARKS_IBUG68][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKigHh-alOKu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's have a look, how landmarks look in 3D.\n",
    "\n",
    "We use ploply to visualise 3D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9mm99k9lOKu",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5igQIqrClOKu",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x, y, z =  np.array(list(item[Modality.LANDMARKS_3D_IBUG68].values()), dtype=np.float64).transpose()\n",
    "lid = list(item[Modality.LANDMARKS_3D_IBUG68].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRx4lZZIlOKv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's visualize landmarks with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "2UHM80pilOKv",
    "outputId": "b4312083-e824-43cf-b6b6-0532656bc580",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, text=lid, mode='markers+text', marker={\"size\": 2})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"iBUG68 3D labeled\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IujMs627lOKv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And without them for more clarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "jOgmnWxjlOKv",
    "outputId": "bc3afee5-5dbf-4cfa-abb5-c55783edb453",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers+text', marker={\"size\": 2})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"iBUG68 3D\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uup_Zqu4lOKv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can project all the landmarks to the screen and check that position is correct on the image as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSz7961mlOKv",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPbKKNQnlOKv",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def landmark_show(img, landmarks, radius=2, labels=True):\n",
    "    l_img = np.copy(img)\n",
    "    for x, y in landmarks:\n",
    "        int_p = (int(x), int(y))\n",
    "        cv2.circle(l_img, int_p, radius=radius, color=(255, 0, 0), thickness=cv2.FILLED)\n",
    "    plt.imshow(l_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wS1Nk2yMlOKw",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "landmarks_2D = cam_to_screen(intrinsics, np.array(list(item[Modality.LANDMARKS_3D_IBUG68].values()), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "_BF4WEYmlOKw",
    "outputId": "30fc8516-1a82-4942-dc17-760947f5a92e",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "landmark_show(item[Modality.RGB], landmarks_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2mS7Gv6lOKw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From intrinsic transform we can compute reverse intrinsic transform, which is needed to map points from the image to 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TFzPvwNlOKw",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rev_intrinsics = np.linalg.inv(intrinsics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs0LjTW1lOKw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Screen coordinates are equivealent to the pixel position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLSsOrq1lOKw",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "shape = item[Modality.RGB].shape\n",
    "screen_xs, screen_ys = np.meshgrid(np.linspace(0, shape[1] - 1, shape[1]),\n",
    "                                   np.linspace(0, shape[0] - 1, shape[0]))\n",
    "depth = item[Modality.DEPTH]\n",
    "color = item[Modality.RGB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MGnFkX8lOKw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To apply reverse projection we need to homogenize the coordinates and multiply them by reversed intrinsic matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNZ-TqxUlOKx",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "xs, ys, zs = np.moveaxis(np.tensordot(np.stack([screen_xs * depth, screen_ys * depth, depth]), rev_intrinsics, axes=(0, 1)), -1, 0) * np.array([1,-1,-1]).reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz9Z6mvHlOKx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can show point cloud of the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeWBcRyClOKx",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=xs[zs<0], y=ys[zs<0], z=zs[zs<0],\n",
    "                                   mode='markers+text', marker={\"size\": 1, \"color\": color[zs<0]})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"Head 3D reconstruction\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1vWBb3wlOKx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To check that everything is correct let's display landmarks at the same 3D plot as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1O4SqPMdlOKx",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x, y, z =  np.array(list(item[Modality.LANDMARKS_3D_IBUG68].values()), dtype=np.float64).transpose()\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=xs[zs<0], y=ys[zs<0], z=zs[zs<0],\n",
    "                                   mode='markers+text', marker={\"size\": 1, \"color\": color[zs<0]}),\n",
    "                      go.Scatter3d(x=x, y=y, z=z, mode='markers+text', marker={\"size\": 3})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"Head 3D reconstruction with landmarks\",\n",
    "                  showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7ztBelJlOKx",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7Vxy5KcnY26",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let't consider dense landmarks. There are 2 types of them: Modality.LANDMARKS_DENSE_MEDIAPIPE, Modality.LANDMARKS_DENSE_SAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0o0yup1n0Rh",
    "outputId": "35f6990f-25c6-4b24-ba96-dbdb6f8eb00c",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "lm_dense_mediapipe = item[Modality.LANDMARKS_3D_MEDIAPIPE_FACE]\n",
    "lm_dense_sai = item[Modality.LANDMARKS_3D_SAI]\n",
    "print(f\"Shapes are: {lm_dense_mediapipe.shape} and {lm_dense_sai.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCseUzhOoSdh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Both types are in camera coordinate sysmet, so we can draw them as previous 3d_IBUG landmarks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "vfXXLvKWofWY",
    "outputId": "cf059414-4d3c-44fd-818d-c2c7630051ce",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "landmark_show(item[Modality.RGB], cam_to_screen(intrinsics, lm_dense_mediapipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "sNlZT_bIpCt3",
    "outputId": "c16b9820-88a6-4bc0-c6c5-79de4b1d5d51",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "landmark_show(item[Modality.RGB], cam_to_screen(intrinsics, lm_dense_sai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "H1V4EgF_pLpp",
    "outputId": "9cda5c45-237b-4839-f6cd-433bcc12e2e5",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x,y,z = lm_dense_mediapipe.transpose()\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers+text', marker={\"size\": 2})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"DENSE_MEDIAPIPE\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "jcxLE0_-pfT_",
    "outputId": "4081c869-4614-485c-8d63-9551f7dceba4",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x,y,z = lm_dense_sai.transpose()\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers+text', marker={\"size\": 2})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"DENSE_SAI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3D space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section we will use two different cameras, align them and reconstruct 3D view of the scene."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Reinit some previouse functions if you have started from this chapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from face_api_dataset import FaceApiDataset, Modality\n",
    "\n",
    "def opengl_to_opencv(x):\n",
    "    return np.array(x) * [1, -1, -1]\n",
    "\n",
    "def cam_to_hom_screen(intrinsics, x):\n",
    "    return np.tensordot(opengl_to_opencv(x), intrinsics, axes=(-1, 1))\n",
    "\n",
    "def from_homogeneous_2D(xs):\n",
    "    xs_array = np.array(xs)\n",
    "    assert (xs_array.shape[-1] == 3)\n",
    "\n",
    "    slice_but_last = [slice(None)] * (xs_array.ndim - 1) + [slice(None, -1)]\n",
    "    slice_but_last = tuple(slice_but_last)\n",
    "\n",
    "    slice_last = [slice(None)] * (xs_array.ndim - 1) + [slice(-1, None)]\n",
    "    slice_last = tuple(slice_last)\n",
    "    return xs_array[slice_but_last] / xs_array[slice_last]\n",
    "\n",
    "def cam_to_screen(intrinsics, x):\n",
    "    return from_homogeneous_2D(cam_to_hom_screen(intrinsics, x))\n",
    "\n",
    "def landmark_show(img, landmarks, radius=2, labels=True):\n",
    "    l_img = np.copy(img)\n",
    "    for x, y in landmarks:\n",
    "        int_p = (int(x), int(y))\n",
    "        cv2.circle(l_img, int_p, radius=radius, color=(255, 0, 0), thickness=cv2.FILLED)\n",
    "    plt.imshow(l_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_root_person = \"test_dataset_2\"\n",
    "dataset_person = FaceApiDataset(data_root_person,\n",
    "                        modalities=[Modality.RGB,\n",
    "                                    Modality.CAM_INTRINSICS,\n",
    "                                    Modality.LANDMARKS_3D_IBUG68,\n",
    "                                    Modality.LANDMARKS_IBUG68,\n",
    "                                    Modality.DEPTH,\n",
    "                                    Modality.CAM_TO_HEAD,\n",
    "                                    Modality.CAM_TO_WORLD,\n",
    "                                    Modality.WORLD_TO_CAM,\n",
    "                                    Modality.LANDMARKS_3D_KINECT_V2,\n",
    "                                    Modality.LANDMARKS_KINECT_V2,\n",
    "                                   ])\n",
    "len(dataset_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Dataset overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cameras_matrixes = []\n",
    "for item_idx in range(len(dataset_person)):\n",
    "    item = dataset_person[item_idx]\n",
    "    intrinsics = item[Modality.CAM_INTRINSICS]\n",
    "    # landmarks_2D = cam_to_screen(intrinsics, np.array(list(item[Modality.LANDMARKS_3D_IBUG68].values()), dtype=np.float64))\n",
    "    landmarks_2D = cam_to_screen(intrinsics, np.array(list(item[Modality.LANDMARKS_3D_KINECT_V2].values()), dtype=np.float64))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    landmark_show(item[Modality.RGB], landmarks_2D, radius=10)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lets plot 2 items in the same 3D space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_3D_points(item):\n",
    "    intrinsics = item[Modality.CAM_INTRINSICS]\n",
    "    rev_intrinsics = np.linalg.inv(intrinsics)\n",
    "    c2w = item[Modality.CAM_TO_WORLD]\n",
    "\n",
    "    shape = item[Modality.RGB].shape\n",
    "    depth = item[Modality.DEPTH]\n",
    "    color = item[Modality.RGB]\n",
    "    landmarks_3D = np.array(list(item[Modality.LANDMARKS_3D_KINECT_V2].values()), dtype=np.float64)\n",
    "    landmarks_2D = np.array(list(item[Modality.LANDMARKS_KINECT_V2].values()), dtype=np.float64)\n",
    "\n",
    "    screen_xs, screen_ys = np.meshgrid(\n",
    "        np.linspace(0, shape[1] - 1, shape[1]),\n",
    "        np.linspace(0, shape[0] - 1, shape[0]))\n",
    "\n",
    "    focal_length_p = intrinsics[0,0]\n",
    "    depth_new = depth / np.sqrt(((((screen_xs - 640) ** 2 + (screen_ys - 400) ** 2) ** 0.5) / focal_length_p) ** 2 + 1)\n",
    "\n",
    "    screen_xs = screen_xs.reshape(-1)\n",
    "    screen_ys = screen_ys.reshape(-1)\n",
    "    depth_new = depth_new.reshape(-1)\n",
    "    color = color.reshape(-1, 3)\n",
    "\n",
    "    xs, ys, zs = np.dot(rev_intrinsics, np.vstack([screen_xs * depth_new, screen_ys * depth_new, depth_new])) * np.array([1,-1,-1]).reshape(-1, 1)\n",
    "    xs, ys, zs = np.dot(c2w, np.vstack([xs, ys, zs, np.ones_like(zs)]))[:3]\n",
    "\n",
    "    xl, yl, zl = landmarks_3D.T\n",
    "    xl, yl, zl = np.dot(c2w, np.vstack([xl, yl, zl, np.ones_like(zl)]) )[:3]\n",
    "    \n",
    "    return (xs, ys, zs, color), (xl, yl, zl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "(xs0, ys0, zs0, color0), (xl0, yl0, zl0) = get_3D_points(dataset_person[0])\n",
    "(xs1, ys1, zs1, color1), (xl1, yl1, zl1) = get_3D_points(dataset_person[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stride=10\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(x=xs0[zs0<1][::stride], y=ys0[zs0<1][::stride], z=zs0[zs0<1][::stride],\n",
    "                                   mode='markers+text', marker={\"size\": 1,\n",
    "                                                                \"color\": color0[zs0<1][::stride],\n",
    "                                                               }),\n",
    "        go.Scatter3d(x=xs1[zs1<1][::stride], y=ys1[zs1<1][::stride], z=zs1[zs1<1][::stride],\n",
    "                                   mode='markers+text', marker={\"size\": 1,\n",
    "                                                                \"color\": color1[zs1<1][::stride],\n",
    "                                                               }),\n",
    "        go.Scatter3d(x=xl0, y=yl0, z=zl0,\n",
    "                                   mode='markers+text', marker={\"size\": 3,\n",
    "                                                                \"color\": np.repeat(np.array([[255,0,0]]), len(zl0), 0),\n",
    "                                                               }),\n",
    "        go.Scatter3d(x=xl1, y=yl1, z=zl1,\n",
    "                                   mode='markers+text', marker={\"size\": 3,\n",
    "                                                                \"color\": np.repeat(np.array([[0,0,255]]), len(zl1), 0),\n",
    "                                                               }),\n",
    "    ])\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    "    height=500,\n",
    "    scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                  \"up\": {\"x\": 0, \"y\": 1, \"z\": -2}},\n",
    "                  title=\"3D space\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "intrinsics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}